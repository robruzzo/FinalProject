{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Robert E Ruzzo III\n",
    "Classify.ipynb\n",
    "\n",
    "The purpose of this notebook is to batch classify unlabeled images\n",
    "\n",
    "\"\"\"\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Configuration\n",
    "Used to hold variable values making them easier to change if needed.\n",
    "\n",
    "    Args: \n",
    "        None\n",
    "\n",
    "Variables:\n",
    "    batch_size (int): The batch processing size\n",
    "    data (string): The location of the training set labels csv\n",
    "    data_dir (string): The directory which containes the subdirectories of the photos to be analzed. \n",
    "        For this notebook to work correctly the pictures have to divided into a sub directories based on their class.\n",
    "    sample_sub (string):The directory that the submission example csv is located\n",
    "\n",
    "\"\"\"\n",
    "class Configuration:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 128\n",
    "        self.data_dir = '/floyd/input/cancer_histo/test'\n",
    "        self.sample_sub = '/floyd/input/cancer_histo/sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a configuration class instance\n",
    "config= Configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Pretrained Model\n",
    "histo_model = keras.models.load_model('DoubleLayers_Crop96_40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv2D)              (None, 94, 94, 256)       7168      \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 92, 92, 256)       590080    \n",
      "_________________________________________________________________\n",
      "pool_1 (MaxPooling2D)        (None, 46, 46, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              (None, 44, 44, 128)       295040    \n",
      "_________________________________________________________________\n",
      "conv_5 (Conv2D)              (None, 42, 42, 128)       147584    \n",
      "_________________________________________________________________\n",
      "pool_2 (MaxPooling2D)        (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_6 (Conv2D)              (None, 19, 19, 64)        73792     \n",
      "_________________________________________________________________\n",
      "pool_3 (MaxPooling2D)        (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 5184)              0         \n",
      "_________________________________________________________________\n",
      "fc_1 (Dense)                 (None, 1024)              5309440   \n",
      "_________________________________________________________________\n",
      "softmax (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 6,425,154\n",
      "Trainable params: 6,425,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Show the summary of the pretrained model\n",
    "histo_model.summary()\n",
    "#Uncomment the next line to view the weights\n",
    "#histo_model.get_weights() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "setup_data : Function\n",
    "Used to setup the imagedatagenerator iterables for batch classification\n",
    "\n",
    "    Args: \n",
    "        test_data_dir (string): The directory that contains a subdirectory with the images. IT IS NECESSARY that there\n",
    "            is a parent level of directory instead of base directory of the images. Otherwise the generator will not \n",
    "            work correctly\n",
    "\n",
    "    Returns:\n",
    "        test_generator (iterable image generator) : An interable generator object for batch image classification\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "def setup_data(test_data_dir):\n",
    "    \n",
    "    test_datagen = ImageDataGenerator(rescale=1.0/255) # Only scaling is performed\n",
    "    \n",
    "\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        batch_size=config.batch_size,\n",
    "        target_size=(96,96),\n",
    "        class_mode=None,\n",
    "        shuffle = False)\n",
    "    \n",
    "    \n",
    "    return test_generator\n",
    "    #return the cropping generator and the number of items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup our test generator iterable\n",
    "test_gen= setup_data(config.data_dir)\n",
    "#Calculate the steps\n",
    "steps = test_gen.n//config.batch_size + 1 \n",
    "'''\n",
    "    Note: If you get less than the number of images for results you need to add 1 to the batch number to include the \n",
    "    remainder. A manual check can verify this, if the result of images / batch size doesnt have a remainder of 0 then\n",
    "    it is necessary. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the GPU to calculate the probabilities\n",
    "device_name=\"/gpu:0\"\n",
    "with tf.device(device_name):\n",
    "    probabilities = histo_model.predict_generator(test_gen,steps)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all of the predictions\n",
    "predicts = [p for p in probabilities]\n",
    "#Convert the predictions to 0,1\n",
    "class_preds = np.argmax(predicts, axis=1)\n",
    "#Gather all of the image names, the image names and the probabilites will be in the same order\n",
    "image_names = [\".\".join(f.split(\".\")[:-1]) for f in os.listdir(config.file_dir) if os.path.isfile(os.path.join(config.file_dir,f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the first column of predictions as it is a predictor of negative, we want prediction of positive\n",
    "predictions = np.array(preds)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create a dictionary of the image_name:predictions\n",
    "predicts_dictionary = dict((key, value) for (key, value) in zip(image_names, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the order of the sample submission as it is important for file generation\n",
    "samples = pd.read_csv(config.sample_sub)\n",
    "#Strip off the name of the file and leave the rest\n",
    "sample_list = list(samples.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new list of predictions that follow the order of the sample submission\n",
    "pred_list_cor = [predicts_dictionary.get(id) for id in sample_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe to hold the information for output to a csv\n",
    "submission_dataframe = pd.DataFrame({'id':sample_list,'label':pred_list_cor})\n",
    "\n",
    "# Export to csv\n",
    "submission_dataframe.to_csv('submission.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
