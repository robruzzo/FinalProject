{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Robert E Ruzzo III\n",
    "ModelValidity.ipynb\n",
    "\n",
    "The purpose of this notebook is to utilize several methods to determine model fitness\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)\n",
    "import pandas as pd\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dropout, Input\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "import os\n",
    "import keras\n",
    "from sklearn.metrics import classification_report, confusion_matrix, auc, roc_curve\n",
    "from keras import metrics\n",
    "from keras import backend as b\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Configuration\n",
    "Used to hold variable values making them easier to change if needed.\n",
    "\n",
    "    Args: \n",
    "        None\n",
    "\n",
    "Variables:\n",
    "    batch_size (int): The batch processing size\n",
    "    data (string): The location of the training set labels csv\n",
    "    data_dir (string): The directory which containes the subdirectories of the photos to be analzed. \n",
    "        For this notebook to work correctly the pictures have to divided into a sub directories based on their class.\n",
    "    image_width (int): expexted width of the image being processed\n",
    "    image_height (int): expected height of the image being processed\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "class Configuration:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 128\n",
    "        #self.data = pd.read_csv('/floyd/input/cancer_histo/train_labels.csv')\n",
    "        self.data = pd.read_csv('D:\\\\Datasets\\\\histopathologic-cancer-detection\\\\train_labels.csv')\n",
    "        #self.data_dir = '/floyd/input/cancer_histo/train'\n",
    "        self.data_dir = 'D:\\\\Datasets\\\\histopathologic-cancer-detection\\\\train\\\\'\n",
    "        self.image_width = 96\n",
    "        self.image_height = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f38a6374c348f90b587e046aac6079959adf3835</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c18f2d887b7ae4f6742ee445113fa1aef383ed77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>755db6279dae599ebb4d39a9123cce439965282d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bc3f0c64fb968ff4a8bd33af6971ecae77c75e08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>068aba587a4950175d04c680d38943fd488d6a9d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  label\n",
       "0  f38a6374c348f90b587e046aac6079959adf3835      0\n",
       "1  c18f2d887b7ae4f6742ee445113fa1aef383ed77      1\n",
       "2  755db6279dae599ebb4d39a9123cce439965282d      0\n",
       "3  bc3f0c64fb968ff4a8bd33af6971ecae77c75e08      0\n",
       "4  068aba587a4950175d04c680d38943fd488d6a9d      0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "auc\n",
    "This was used for custom metrics AUC generation and is necessary when any model using that is loaded\n",
    "\n",
    "    Args: \n",
    "        y_true (int):The base truth class of the image\n",
    "        y_predicted (int): The predicted class of the image\n",
    "\n",
    "Variables:\n",
    "    \n",
    "    auc : calculated area under the curve returned from tensorflow auc method\n",
    "    \n",
    "\"\"\"\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    b.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment if using a custom metric, make sure the custom metric is defined in this notebook\n",
    "#keras.losses.custom_metrics = auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exclude the image that throws exceptions when loaded\n",
    "config.data=config.data[config.data.id != 'b44ceb87f4fb92169ec928c652d6e1209b48135c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"setup_data - Function creates the generators which add data variance and cropping capabilities\n",
    "    Note: This function has to return the number of items in the iterables to ensure functionality with the \n",
    "    fit function.\n",
    "\n",
    "    Args:\n",
    "        train_data_dir (string) : directory that the training and validation data are located\n",
    "        batch_size (int) : size of the batches (count)\n",
    "\n",
    "    Returns:\n",
    "        traing_cropped (iterable image generator) : cropped and augmented training images\n",
    "        validation_cropped (iterable image generator) : cropped and augmented validation images\n",
    "        train_generator.n (int) : The number of items in the training generator iterable\n",
    "        validation_generator.n (int): The number of items in the validation generator iterable\n",
    "\n",
    "    \"\"\"\n",
    "#Setup data, and create split for training, testing 80/20\n",
    "def setup_data(train_data_dir, batch_size):\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=0.2) # set validation split\n",
    "\n",
    "    validation_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        batch_size=batch_size,\n",
    "        target_size=(96,96),\n",
    "        class_mode='categorical',\n",
    "        subset='validation')\n",
    "    \n",
    "    return  validation_generator, validation_generator.n\n",
    "    #return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "histo_model = keras.models.load_model('DoubleLayers_Crop96_40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histo_model = keras.models.load_model('double_no_crop_auc_10', custom_objects={'auc': auc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"eval_model : This function uses the output of fit_model to evaluate the model after training is complete,\n",
    "    and shows validation accuracy and validation loss as parameters.\n",
    "\n",
    "    Args:\n",
    "        model (Keras/TensorFlow model object) : The trained model output from fit_model\n",
    "        val_generator (iterable image generator object) : The iterable validation generator from the setup_data function\n",
    "        batch_size (int) : The batch size, or number of objects processed with each batch iteration.\n",
    "        \n",
    "    Returns:\n",
    "        None, output is printed\n",
    "\n",
    "    \"\"\"\n",
    "def eval_model(model, val_generator, batch_size):\n",
    "    scores = model.evaluate_generator(val_generator, steps=val_n // batch_size +1)\n",
    "    print(\"Loss: \" + str(scores[0]) + \" Accuracy: \" + str(scores[1]))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create instance of the val_generator\n",
    "val_generator, val_n= setup_data(config.data_dir, batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model.\n",
    "device_name=\"/gpu:0\"\n",
    "with tf.device(device_name):\n",
    "    score = eval_model(histo_model, val_generator, batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confution Matrix and Classification Report\n",
    "Y_pred = histo_model.predict_generator(val_generator, val_n // config.batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print out the confusion matrix\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(val_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['No_Tumor', 'Tumor']\n",
    "print(classification_report(val_generator.classes, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
